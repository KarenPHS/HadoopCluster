{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"gbt\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yarn mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config('spark.executor.instances','99')\\\n",
    "        .config('spark.executor.memory','4G')\\\n",
    "        .appName(\"iris\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check spark app name\n",
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5 (default, Jul 28 2020, 12:59:40) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print runtime versions\n",
    "# Python version\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris.csv into Spark dataframe\n",
    "#df = spark.read.csv('file:///vagrant/data/bike/hour.csv', header=True, inferSchema=True)\n",
    "df = spark.read.csv('data/bike/hour.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the size of data\n",
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "|instant|    dteday|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|casual|registered|cnt|\n",
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "|      1|2011-01-01|     1|  0|   1|  0|      0|      6|         0|         1|0.24|0.2879|0.81|      0.0|     3|        13| 16|\n",
      "|      2|2011-01-01|     1|  0|   1|  1|      0|      6|         0|         1|0.22|0.2727| 0.8|      0.0|     8|        32| 40|\n",
      "|      3|2011-01-01|     1|  0|   1|  2|      0|      6|         0|         1|0.22|0.2727| 0.8|      0.0|     5|        27| 32|\n",
      "|      4|2011-01-01|     1|  0|   1|  3|      0|      6|         0|         1|0.24|0.2879|0.75|      0.0|     3|        10| 13|\n",
      "|      5|2011-01-01|     1|  0|   1|  4|      0|      6|         0|         1|0.24|0.2879|0.75|      0.0|     0|         1|  1|\n",
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First 5 rows of Iris dataset\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- instant: integer (nullable = true)\n",
      " |-- dteday: string (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- yr: integer (nullable = true)\n",
      " |-- mnth: integer (nullable = true)\n",
      " |-- hr: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weathersit: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- hum: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- cnt: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---+\n",
      "|casual|registered|cnt|\n",
      "+------+----------+---+\n",
      "|     3|        13| 16|\n",
      "|     8|        32| 40|\n",
      "|     5|        27| 32|\n",
      "|     3|        10| 13|\n",
      "|     0|         1|  1|\n",
      "|     0|         1|  1|\n",
      "|     2|         0|  2|\n",
      "|     1|         2|  3|\n",
      "|     1|         7|  8|\n",
      "|     8|         6| 14|\n",
      "+------+----------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('casual', 'registered', 'cnt').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard 'instant', 'dteday', 'casual' and 'registered' columns\n",
    "df = df.drop('instant').drop('dteday').drop('casual').drop('registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\n",
      "|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|cnt|\n",
      "+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\n",
      "|     1|  0|   1|  0|      0|      6|         0|         1|0.24|0.2879|0.81|      0.0| 16|\n",
      "|     1|  0|   1|  1|      0|      6|         0|         1|0.22|0.2727| 0.8|      0.0| 40|\n",
      "|     1|  0|   1|  2|      0|      6|         0|         1|0.22|0.2727| 0.8|      0.0| 32|\n",
      "|     1|  0|   1|  3|      0|      6|         0|         1|0.24|0.2879|0.75|      0.0| 13|\n",
      "|     1|  0|   1|  4|      0|      6|         0|         1|0.24|0.2879|0.75|      0.0|  1|\n",
      "|     1|  0|   1|  5|      0|      6|         0|         2|0.24|0.2576|0.75|   0.0896|  1|\n",
      "|     1|  0|   1|  6|      0|      6|         0|         1|0.22|0.2727| 0.8|      0.0|  2|\n",
      "|     1|  0|   1|  7|      0|      6|         0|         1| 0.2|0.2576|0.86|      0.0|  3|\n",
      "|     1|  0|   1|  8|      0|      6|         0|         1|0.24|0.2879|0.75|      0.0|  8|\n",
      "|     1|  0|   1|  9|      0|      6|         0|         1|0.32|0.3485|0.76|      0.0| 14|\n",
      "+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- season: integer (nullable = true)\n",
      " |-- yr: integer (nullable = true)\n",
      " |-- mnth: integer (nullable = true)\n",
      " |-- hr: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weathersit: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- hum: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- cnt: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Logistic Regression to train on the training set\n",
    "train_df, test_df = df.randomSplit([0.70, 0.30], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12234, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5145, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count(), len(test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build GBT Regression Model using Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCols = df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'hr',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates all feature columns into a single feature vector\n",
    "vectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the \"features\" column and learns to predict \"cnt\"\n",
    "gbt = GBTRegressor(labelCol=\"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(gbt.maxDepth, [2, 5])\\\n",
    "    .addGrid(gbt.maxIter, [10, 100])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation metric  \n",
    "# tell CrossValidator how well we are doing by comparing the true labels with predictions\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", \n",
    "            labelCol=gbt.getLabelCol(), \n",
    "            predictionCol=gbt.getPredictionCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the CrossValidator, which runs model tuning for us\n",
    "cv = CrossValidator(estimator=gbt, evaluator=evaluator, \n",
    "        estimatorParamMaps=paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tie feature processing and model training stages together into a single Pipeline\n",
    "pipeline = Pipeline(stages=[vectorAssembler, cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 386 ms, sys: 148 ms, total: 534 ms\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the Pipeline\n",
    "pipelineModel = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel.stages[1].bestModel._java_obj.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel.stages[1].bestModel._java_obj.getMaxIter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data \n",
    "predictions = pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|cnt|prediction        |\n",
      "+---+------------------+\n",
      "|33 |33.19305689960539 |\n",
      "|5  |9.287642994994783 |\n",
      "|7  |16.7675170064617  |\n",
      "|12 |9.652341195079874 |\n",
      "|7  |7.555943059568435 |\n",
      "|17 |15.845011568803482|\n",
      "|3  |16.058875542147785|\n",
      "|14 |12.691276974128776|\n",
      "|9  |11.87620282915386 |\n",
      "|13 |26.12295702251729 |\n",
      "+---+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the residual errors based on predictions \n",
    "predictions.select('cnt', 'prediction').show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.073736367721025"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
